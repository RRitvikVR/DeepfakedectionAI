{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-GcLWOT8tuT"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "#Display time to run script\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCvtjbZ9826a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "username = 'atbusch78'\n",
        "git_token = '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'\n",
        "repository = 'Neural-Nets-2025'\n",
        "\n",
        "!git clone --depth=1 https://{git_token}@github.com/{username}/{repository}.git\n",
        "dataset_path = \"/content/Neural-Nets-2025/Project/archive\"\n",
        "\n",
        "def find_folder(base_path, target_folder):\n",
        "    for item in os.listdir(base_path):\n",
        "        if item.upper() == target_folder.upper():\n",
        "            return os.path.join(base_path, item)\n",
        "    raise FileNotFoundError(f\"Could not find {target_folder} in {base_path}\")\n",
        "\n",
        "# Find paths\n",
        "train_real_path = find_folder(os.path.join(dataset_path, \"train\"), \"REAL\")\n",
        "train_fake_path = find_folder(os.path.join(dataset_path, \"train\"), \"FAKE\")\n",
        "test_real_path = find_folder(os.path.join(dataset_path, \"test\"), \"REAL\")\n",
        "test_fake_path = find_folder(os.path.join(dataset_path, \"test\"), \"FAKE\")\n",
        "\n",
        "# --- New Code ---\n",
        "# Feature Extractor\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove classifier head\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def extract_features_from_folder(folder_path, label, max_images=None):\n",
        "    features, labels = [], []\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    if max_images is not None:\n",
        "        image_files = image_files[:max_images]  # Only take up to max_images\n",
        "\n",
        "    for img_name in tqdm(image_files, desc=f\"Extracting from {folder_path}\"):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img = transform(img).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                feat = resnet(img)\n",
        "            features.append(feat.cpu().numpy().flatten())\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {img_name}: {e}\")\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# --- Extract features with limits ---\n",
        "X_train_real, y_train_real = extract_features_from_folder(train_real_path, label=1, max_images=4000)\n",
        "X_train_fake, y_train_fake = extract_features_from_folder(train_fake_path, label=0, max_images=4000)\n",
        "X_test_real, y_test_real = extract_features_from_folder(test_real_path, label=1, max_images=1000)\n",
        "X_test_fake, y_test_fake = extract_features_from_folder(test_fake_path, label=0, max_images=1000)\n",
        "\n",
        "\n",
        "# Stack data\n",
        "X_train = np.vstack([X_train_real, X_train_fake])\n",
        "y_train = np.concatenate([y_train_real, y_train_fake])\n",
        "\n",
        "X_test = np.vstack([X_test_real, X_test_fake])\n",
        "y_test = np.concatenate([y_test_real, y_test_fake])\n",
        "\n",
        "# --- Random Forest Training ---\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluation ---\n",
        "y_pred = rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=[\"FAKE\", \"REAL\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYkAevdXByTQ",
        "outputId": "475ffeba-7c72-41de-b34f-6287f0af09aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 226 ms (started: 2025-04-30 16:25:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the model to a file\n",
        "joblib.dump(rf, \"random_forest_model.pkl\")\n",
        "# Load the model\n",
        "rf_loaded = joblib.load(\"random_forest_model.pkl\")\n",
        "\n",
        "\n",
        "y_pred = rf_loaded.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OShJzfGB139",
        "outputId": "bcd9a38e-779f-4de1-ca62-210cdbf1baed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 7.75 s (started: 2025-04-30 16:25:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXSupZlFB7bj",
        "outputId": "7fd598b6-81b9-41c5-b7e4-6496a460594a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n",
            "time: 21 ms (started: 2025-04-30 16:26:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_PATH = \"random_forest_model.pkl\" # Path to the saved RF model\n",
        "\n",
        "# ***** MOVE THIS LINE UP *****\n",
        "# --- Streamlit Page Configuration (MUST BE FIRST STREAMLIT COMMAND) ---\n",
        "st.set_page_config(\n",
        "    page_title=\"Deepfake Detector\",\n",
        "    page_icon=\"ðŸ–¼ï¸\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "# ***** END OF MOVE *****\n",
        "\n",
        "\n",
        "# --- Load Feature Extractor (ResNet) ---\n",
        "# Re-define the feature extractor setup exactly as in the training notebook\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Use the recommended way to load pretrained weights\n",
        "try:\n",
        "    weights = models.ResNet18_Weights.DEFAULT\n",
        "except AttributeError: # Older torchvision versions might not have DEFAULT\n",
        "     weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
        "\n",
        "resnet = models.resnet18(weights=weights)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1]) # Remove classifier head\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval() # Set to evaluation mode\n",
        "\n",
        "# --- Define Image Transformations ---\n",
        "# Must be the same as used during training feature extraction\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    # Note: Normalization was not explicitly included in the original notebook's transform.\n",
        "    # If features were extracted *without* normalization, keep it commented out.\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- Load Trained Classifier ---\n",
        "@st.cache_resource # Cache the loaded model for efficiency\n",
        "def load_classifier(model_path):\n",
        "    \"\"\"Loads the saved Random Forest classifier.\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        # This st.error() is now fine because set_page_config was called first\n",
        "        st.error(f\"Model file not found at {model_path}. Please ensure the previous notebook cells have run successfully and saved the model.\")\n",
        "        return None\n",
        "    try:\n",
        "        classifier = joblib.load(model_path)\n",
        "        return classifier\n",
        "    except Exception as e:\n",
        "        # This st.error() is now fine\n",
        "        st.error(f\"Error loading the model: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Load the classifier AFTER set_page_config ---\n",
        "classifier = load_classifier(MODEL_PATH)\n",
        "\n",
        "# --- Helper Function ---\n",
        "def predict_image(image_bytes):\n",
        "    \"\"\"Preprocesses image, extracts features, and predicts using the loaded classifier.\"\"\"\n",
        "    if classifier is None:\n",
        "        # This st.error() is now fine\n",
        "        st.error(\"Classifier not loaded. Cannot predict.\")\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        img = Image.open(image_bytes).convert('RGB')\n",
        "\n",
        "        # Apply transformations\n",
        "        img_t = transform(img).unsqueeze(0).to(device) # Add batch dimension and send to device\n",
        "\n",
        "        # Extract features using ResNet\n",
        "        with torch.no_grad():\n",
        "            features = resnet(img_t)\n",
        "\n",
        "        # Prepare features for Random Forest (flatten)\n",
        "        features_np = features.cpu().numpy().flatten().reshape(1, -1) # Reshape for single prediction\n",
        "\n",
        "        # Predict using the loaded Random Forest model\n",
        "        prediction = classifier.predict(features_np)[0] # Get the single prediction\n",
        "        probability = classifier.predict_proba(features_np)[0] # Get probabilities for [FAKE, REAL]\n",
        "\n",
        "        return prediction, probability\n",
        "\n",
        "    except Exception as e:\n",
        "        # This st.error() is now fine\n",
        "        st.error(f\"An error occurred during prediction: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "# set_page_config was moved to the top\n",
        "\n",
        "st.title(\"ðŸ–¼ï¸ Deepfake Image Detector UI\")\n",
        "st.write(\"Upload an image to classify it as REAL or FAKE using a ResNet feature extractor and a Random Forest classifier.\")\n",
        "st.write(f\"*(Using device: {device.upper()})*\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display the uploaded image\n",
        "    st.image(uploaded_file, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\") # Add some space\n",
        "\n",
        "    # Predict on button click\n",
        "    if st.button('Classify Image'):\n",
        "        # Ensure classifier is loaded before attempting prediction in the UI\n",
        "        if classifier is not None:\n",
        "             with st.spinner('Analyzing image...'):\n",
        "                prediction, probability = predict_image(uploaded_file)\n",
        "\n",
        "                if prediction is not None:\n",
        "                    st.subheader(\"Prediction Result:\")\n",
        "                    if prediction == 1:\n",
        "                        st.success(f\"**REAL** (Confidence: {probability[1]:.2%})\")\n",
        "                    else:\n",
        "                        st.error(f\"**FAKE** (Confidence: {probability[0]:.2%})\")\n",
        "        else:\n",
        "            st.error(\"Model could not be loaded. Please check logs and ensure 'random_forest_model.pkl' exists.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload an image file to start classification.\")\n",
        "\n",
        "# Add a footer or sidebar info if desired\n",
        "st.sidebar.header(\"About\")\n",
        "st.sidebar.info(\n",
        "    \"This app uses features extracted by a pre-trained ResNet-18 model, \"\n",
        "    \"which are then fed into a Random Forest classifier trained on a dataset \"\n",
        "    \"of real and fake images (like those generated by StyleGAN).\"\n",
        "    f\"\\n\\nModel file expected: `{MODEL_PATH}`\"\n",
        "    f\"\\nCompute device: `{device.upper()}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXdFMR6hxSRv",
        "outputId": "a968afe2-7db7-4ab6-a21f-30d4d61fce89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing localtunnel...\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "added 22 packages in 6s\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Ktime: 6.56 s (started: 2025-04-30 16:26:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"app.py\"):\n",
        "    print(\"Error: app.py not found. Please run Cell 5 first.\")\n",
        "else:\n",
        "    # Install localtunnel using npm (Node Package Manager)\n",
        "    print(\"Installing localtunnel...\")\n",
        "    !npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdcVWBTuxq9g",
        "outputId": "fc7cfbb2-5703-4861-e066-e96235882de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.138.84.69\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XFRBuOoB8dJ",
        "outputId": "c79f5b46-b643-49af-9f3d-8c686ea49681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to start Streamlit on port 8501 and launch localtunnel...\n",
            "Ensure the cell writing 'app.py' and the cell installing 'localtunnel' have been run successfully.\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kyour url is: https://dirty-donkeys-sin.loca.lt\n"
          ]
        }
      ],
      "source": [
        "# CELL 6: Launch Streamlit and Localtunnel\n",
        "# (Assumes app.py exists and localtunnel is installed from previous cells)\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the port\n",
        "port = 8501 # Streamlit's default port\n",
        "\n",
        "# Run Streamlit in the background & start localtunnel\n",
        "print(f\"Attempting to start Streamlit on port {port} and launch localtunnel...\")\n",
        "print(\"Ensure the cell writing 'app.py' and the cell installing 'localtunnel' have been run successfully.\")\n",
        "\n",
        "# Use nohup to prevent hang-up and redirect stderr to stdout for better logging in Colab\n",
        "# The '&' runs streamlit in the background FIRST, then npx runs in the foreground of the cell\n",
        "!nohup streamlit run app.py --server.port {port} > streamlit_log.txt 2>&1 &\n",
        "\n",
        "# Launch localtunnel - this will now run in the foreground of this cell\n",
        "!npx localtunnel --port {port}\n",
        "\n",
        "# Note: The output below the cell will show the localtunnel URL (e.g., https://<random-word>.loca.lt)\n",
        "# You might need to click through a warning page the first time you access the URL.\n",
        "print(\"\\n----> Look for a URL ending in '.loca.lt' in the output above or below this message. <----\")\n",
        "print(\"      (You might need to scroll up in the output to find it)\")\n",
        "print(\"\\nNote: The UI will become unresponsive if the Colab session ends or this cell is stopped.\")\n",
        "print(\"      If the app seems stuck or shows errors, check the 'streamlit_log.txt' file for details:\")\n",
        "print(\"      !cat streamlit_log.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jqsNS8ZCAD7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}